{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "49e04c00-0013-43e6-9d78-7e08569f9044",
   "metadata": {},
   "source": [
    "# HTTP Requests and Parsing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b6dc4e9-ee75-4bbc-8a48-fd73ba28ce33",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65eb172f-d227-40a8-a7e4-8ba35a2fde66",
   "metadata": {},
   "source": [
    "## HTTP Requests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cc77362-6327-41e6-9f1b-a42ebe4752ce",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f031b357-d617-429d-b51f-1f7f276dd333",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Background Reading\n",
    "- **Internet**--interconnected network of computers that use the internet suite of protocols (TCP/IP) to send and receive information.  It is the infrastructure.\n",
    "- **World Wide Web**--network of web pages that are hosted by web servers and viewed by web browsers. It is the information (files) that is transferred.\n",
    "- **IP Address**-- Internet Protocol Address. It is a unique address given to an electronic device connected to the internet.  It provides a location that data can be sent to.  Like a phone number for a person.\n",
    "- **Port**--number which tells a computer which application on the computer should receive packets of data.  If we compared the IP address to a phone number, the port would be like the extension that got us to the right person.\n",
    "- **Socket**--one endpoint of a two-way communication link between two programs connected to the internet. A socket is bound to a port number. It can be thought of as both the phone number and the phone number extension when there is an active call between two people.\n",
    "    - **Transport Layer Security (TLS)**--protocols for establishing authenticated and encrypted links between computers connected to the internet. It is what makes HTTPS secure.  It is the successor to the **Secure Sockets Layer (SSL)**, which is now deprecated. \n",
    "- **HTTP and HTTPS**--HyperText Transfer Protocol. Is is the protocol that specifies how web browsers and web servers send and receive data back and forth across the Internet.  The S in HTTPS stands for secure.  HTTPS is used any time sensitive information is transferred across the internet.\n",
    "- **HTML**--Hypertext Markup Language.  Language used to specify the text of a webpage, format of a webpage, and hyperlink web pages together.  HTML files end with .html.  These files are the main resources that are transferred across the internet.  However, in today's age, we are also transferring CSS, XML, JSON, JS, and binary files (media, compressed program files, etc.) frequently. \n",
    " - **URL**--Uniform Resource Locator.  Contains address/location of a web server that has a resource (like HTML files).  The domain name is a unique name that humans can remember and is converted into an IP address for computers to use.  URL also contains the method for retrieving the resource (file).  HTTP or HTTPS are the methods.  Note that the port is often left out as it is always port 80 for HTTP and port 443 for HTTPS.\n",
    "    - ![](images/URLimage.png)\n",
    "    - The URL above tells a web browser to use HTTP, go to a certain web server computer (domain/IP address), go to the correct application on that web server computer (port), and then go to the correct file (file path) on that web server computer to GET the resource (HTML file).\n",
    "    - If it all works out, we'll get a \"200 OK\" status code called a **header** as part of the information we receive back.  If there is an error we may get back the \"404 not found\" status code header.\n",
    "- More information is served from web servers to web browsers, but it is a two way communication.  We the users send requests for files to a web server using HTTP(S).  This communication follows a request, response pattern.  We request something from a web server and wait for it to respond.  The most used HTTP request is called the GET method.  We try and GET data from a web server. Normally, we do this without thinking about it by Googling a webpage and clicking on links.  However, we can do this in a more intentional way using a programming language.\n",
    "    1. Single GET request.  We may want to request a single web page file.  We'll be doing this below.\n",
    "    1. **Scrape**--a script sends a GET request to a webpage, downloads the HTML file, and saves this info to a database.  It looks for hyperlinks on the downloaded copy, then sends GET requests to new webpages. GET requests, download, find links, repeat.  The term scraping often implies that we are targeting certain websites and file types to download.  On a smaller scale than *crawl*.\n",
    "    1. **Crawl**--also called spider.  Same as scrape, but term often implies we are navigating and downloading lots of web pages.  If we wanted to build an index for a search engine we'd  *crawl* over all the pages on the world wide web."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeadbb40-ee33-480c-9695-f9b758b141d2",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd61f9fa-d3fe-4d6f-93fb-1568766096cd",
   "metadata": {},
   "source": [
    "### HTTP Get Requests\n",
    "- We can send a single GET request in a handful of ways.  As the internet has evolved, new Python libraries have been created that perform requests in a more Pythonic way with more functionality.  We'll cover 5 ways to send HTTP get requests, but we really only need to know the `requests` library."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61892112-1c65-44ee-9fbf-0fd861375b4c",
   "metadata": {},
   "source": [
    "**5 WAYS to SEND HTTP GET REQUESTS**\n",
    "\n",
    "1.  **Telnet**--old program that can open a socket to a host on a port.  Potential security risk, so it was removed from all Windows CPs.\n",
    "\n",
    "2. **Web Browser Developer Tools**--send HTTP requests using a web browser.  This can actually be helpful if we want to double check our Python code.\n",
    "    1. Go to a website in a web browser\n",
    "    1. In Mozilla, enable the menu bar by right clicking on the top row where the tabs are\n",
    "    1. Tools> Web Developer> Web Developer Tools\n",
    "    1. Refresh web browser\n",
    "    1. Click Network\n",
    "    1. Click a row.  This sends a GET request.\n",
    "    1. View the headers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8226348-a369-4906-b6ab-234b0a741ad2",
   "metadata": {},
   "source": [
    "3. **`socket`**--old and verbose.  Not used today, but helps us understand what's going on under the hood.\n",
    "    1. Import socket module\n",
    "    2. Create socket object\n",
    "    3. Specify domain and port that socket object will be connected to\n",
    "    4. Encode data.  Convert Unicode string to bytes (UTF-8).  When we talk to an external resource like a network we send bytes (UTF-8).\n",
    "    5. Send data\n",
    "    6. Receive data\n",
    "    7. Decode data.  Convert bytes (UTF-8) to Unicode string.  When we receive data from an external resource like a network we receive bytes (UTF-8).\n",
    "    8. Close network socket connection\n",
    "\n",
    "Code | Use\n",
    "--- | ---\n",
    "`socket` | Module\n",
    "`socket.socket()` | Returns socket object. Similar to a file object/handle.  In a nutshell parameters mean that we are going to have a stream of communication with a socket object and we are going to connect over the internet.  Don't need to fully understand to use.\n",
    "`.connect()` | Socket object method.  Connects to the socket object.  It is kinda like the second step of getting the socket object ready before we can communicate with socket.  We specify which socket we want to connect to by using the parameters (website domain, port).  This is similar to typing a URL into web browser.\n",
    "`.encode()` | String object method.  Converts Unicode string to bytes/byte object using UTF-8\n",
    "`.send()` | Socket object method.  Sends byte object command to web server.  Parameter is the command created above.\n",
    "`.recv()` | Socket object method.  Receives byte object data from web server.  Parameter is the max numbers of characters we wish to receive  at one time in one chunk.  Called buffer (buff) size.  It is common for buffer to be a relatively small power of 2, for example 4096.\n",
    "`.decode()` | Bytes object method.  Converts bytes/byte object to Unicode string using UTF-8\n",
    "`.close()` | Socket object method.  Closes network socket connection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e0b7cc8-8380-42f8-acbd-e29d9170a607",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53f7fa8e-200f-4504-94d6-2f6fb39b49e0",
   "metadata": {},
   "source": [
    "**EXAMPLES**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e6d034e-db0b-4734-8e7c-8917b9df9e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import socket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "914ff359-267a-4b01-9d46-8614d5abc77c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP/1.1 200 OK\n",
      "Date: Sun, 02 Jan 2022 21:06:28 GMT\n",
      "Server: Apache/2.4.18 (Ubuntu)\n",
      "Last-Modified: Sat, 13 May 2017 11:22:22 GMT\n",
      "ETag: \"a7-54f6609245537\"\n",
      "Accept-Ranges: bytes\n",
      "Content-Length: 167\n",
      "Cache-Control: max-age=0, no-cache, no-store, must-revalidate\n",
      "Pragma: no-cache\n",
      "Expires: Wed, 11 Jan 1984 05:00:00 GMT\n",
      "Connection: close\n",
      "Content-Type: text/plain\n",
      "\n",
      "But soft what light through yonder window breaks\n",
      "It is the east and Juliet is the sun\n",
      "Arise fair sun and kill the envious moon\n",
      "Who is already s\n",
      "ick and pale with grief\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<bound method socket.close of <socket.socket fd=1360, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('192.168.7.68', 58234), raddr=('192.241.136.170', 80)>>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
    "sock.connect(('data.pr4e.org', 80))\n",
    "http_get_method = 'GET http://data.pr4e.org/romeo.txt HTTP/1.0\\r\\n\\r\\n'.encode()\n",
    "sock.send(http_get_method) \n",
    "\n",
    "while True:\n",
    "    data = sock.recv(512)\n",
    "    if (len(data) < 1):\n",
    "        break\n",
    "    print(data.decode())\n",
    "sock.close"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "929b61d0-6be9-420d-835f-39b916a82244",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a896b30-895c-4f09-bc8a-c314f7fc0e04",
   "metadata": {},
   "source": [
    "4. **`urllib`**--is made for Python 3.  It is an updated combination of urllib (Python 1.2) and urllib2 (Python 1.6).  Better than `socket`, but still dated and less used.  Creates a file handle that we can use almost exactly like a file handle created with `open()`.  No header info by default, but can get header information if desired.\n",
    "\n",
    "Code | Use\n",
    "--- | ---\n",
    "`urllib` | Library\n",
    "`urllib.reqest` | Dot notation specifies `request` module within `urllib` library.  Need this for VS code.  This request module is different from the requests library found below.\n",
    "`urllib.request.urlopen()` | Creates file object/handle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37618bfb-f3bf-41f1-a584-87c0c3966ea8",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ae8a873-f32d-4a35-ac3c-fbf00dea99a2",
   "metadata": {},
   "source": [
    "**EXAMPLES**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e331a40a-6dc9-4332-b08c-fba7ce3d8cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib  \n",
    "# Must use dot notation in VS Code to specify requests module within urllib library\n",
    "# import urllib.request"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9ddc749-d1ac-429f-9fa3-a005dcd9e7a2",
   "metadata": {},
   "source": [
    "**`.read()` and `.decode()`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f8f389f5-0fe3-421b-98fa-e8e60e4cde96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "But soft what light through yonder window breaks\n",
      "It is the east and Juliet is the sun\n",
      "Arise fair sun and kill the envious moon\n",
      "Who is already sick and pale with grief\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Open socket, encode and send GET request, and receive file all in one command\n",
    "fh = urllib.request.urlopen('http://data.pr4e.org/romeo.txt')\n",
    "\n",
    "b_romeo = fh.read()  # Read in bytes from file handle\n",
    "s_romeo = b_romeo.decode()  # Decode bytes to string\n",
    "print(s_romeo)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89357d8d-7baa-4f25-b06e-bd2b216a4461",
   "metadata": {},
   "source": [
    "**`for` loop and `.decode()`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9f974f5e-e71e-4a58-9012-026edea136bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "But soft what light through yonder window breaks\n",
      "It is the east and Juliet is the sun\n",
      "Arise fair sun and kill the envious moon\n",
      "Who is already sick and pale with grief\n"
     ]
    }
   ],
   "source": [
    "# Open socket, encode and send GET request, and receive file all in one command\n",
    "fh = urllib.request.urlopen('http://data.pr4e.org/romeo.txt')\n",
    "\n",
    "for b_line in fh:\n",
    "    print(b_line.decode(), end=\"\")  # Read in bytes from file handle, decode, and print"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13b45046-a77f-4208-b796-2056b31b9b4f",
   "metadata": {},
   "source": [
    "5. **`requests`**--the most popular way.  Use this.  Only library found on W3schools.  Apparently it is built upon a 3rd party package called `urllib3`.  `requests` makes `urllib3` even better.  Similar to `urllib`, in that it creates a file handle.  The `read()`, `readline`, and `readlines` methods do not work with request objects, but for loops do.\n",
    "\n",
    "Code | Use\n",
    "--- | ---\n",
    "`requests` | Library\n",
    "`requests.get('<URL>')` | Return response object.  Send GET request. Parameter is URL.  Optional argument `timeout = <SECONDS>`.  This is the number of seconds `.get()` will wait to receive bytes from the socket before raising a `Timeout` error.  If not included then request could go on indefinitely.  Recommended.\n",
    "`.status_code` | Request object attribute.  Returns HTTP status code.\n",
    "`.raise_for_status()` | Request object method.  Raise an exception if there was an error downloading file.  Does nothing if no error.  Good practice to always run this after HTTP request.  Can run to stop program or can run in try statement.\n",
    "`.url` | Request object attribute.  Returns URL from request.\n",
    "`.headers` | Request object attribute.  Returns Python dictionary of HTTP headers.\n",
    "`.text` | Request object attribute.  Returns response body as Python string.  `requests` module makes an educated guess as to the encoding of the file text (usually UTF-8) based on HTTP headers and decodes bytes automatically.\n",
    "`.encoding` | Request object attribute.  Displays decoding used to create `.text`.\n",
    "`.content` | Request object attribute.  Returns response body as bytes object (bytes).  If `gzip` or `deflate` file transfer encoding, these are decoded for us automatically\n",
    "`.json` | Request object attribute.  Returns response body as JSON string.\n",
    "`.iter_content()` | Request object method.  Turns bytes object into iterable object by breaking it up into chunks.  Specify size of chunks in bytes.  `chunk_size = 100000` is usually good.  Used for writing files.\n",
    "`for` | Read in file in for loop.  Like in `socket` and `urllib` we read in bytes from the file.\n",
    "`requests.codes.ok` | Constant that returns value 200"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d5121cc-eb76-40cb-8dec-1ca39e87a010",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b538e0f4-ba75-47f9-a481-2b73d73a9867",
   "metadata": {},
   "source": [
    "**EXAMPLES**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b59360d1-8f40-464b-833b-50554abe19f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "578828c0-8806-4c56-8283-220a7141d6e6",
   "metadata": {},
   "source": [
    "**`.raise_for_status()`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c53768aa-6b83-437f-9c67-dab4f878ab80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The web page could not be reached. 404 Client Error: Not Found for url: https://en.wikipedia.org/BAD_PAGE\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    request_object = requests.get('https://www.wikipedia.org/BAD_PAGE', timeout = 1.0)\n",
    "    request_object.raise_for_status()\n",
    "except Exception as err :\n",
    "    print(f'The web page could not be reached. {err}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75f0546f-d017-4e6b-8646-4777073706b3",
   "metadata": {},
   "source": [
    "**View Metadata**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "822a358a-c283-4802-96ce-ac6f26d12e5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "http://data.pr4e.org/romeo.txt\n",
      "{'Date': 'Sun, 02 Jan 2022 21:06:29 GMT', 'Server': 'Apache/2.4.18 (Ubuntu)', 'Last-Modified': 'Sat, 13 May 2017 11:22:22 GMT', 'ETag': '\"a7-54f6609245537\"', 'Accept-Ranges': 'bytes', 'Content-Length': '167', 'Cache-Control': 'max-age=0, no-cache, no-store, must-revalidate', 'Pragma': 'no-cache', 'Expires': 'Wed, 11 Jan 1984 05:00:00 GMT', 'Keep-Alive': 'timeout=5, max=100', 'Connection': 'Keep-Alive', 'Content-Type': 'text/plain'}\n"
     ]
    }
   ],
   "source": [
    "request_object = requests.get('http://data.pr4e.org/romeo.txt', timeout = 1.0)\n",
    "request_object.raise_for_status()  # No error so nothing done.\n",
    "print(request_object.status_code)\n",
    "print(request_object.url)\n",
    "print(request_object.headers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7761d641-1950-443f-b6c4-9d3416e2cc31",
   "metadata": {},
   "source": [
    "**`.text`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7937870d-0c74-4c56-a8b7-3672a559ade2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ISO-8859-1\n",
      "<class 'str'>\n",
      "But soft what light through yonder window breaks\n",
      "It is the east and Juliet is the sun\n",
      "Arise fair sun and kill the envious moon\n",
      "Who is already sick and pale with grief\n",
      "\n"
     ]
    }
   ],
   "source": [
    "request_object = requests.get('http://data.pr4e.org/romeo.txt', timeout = 1.0)\n",
    "request_object.raise_for_status()  # No error so nothing done.\n",
    "print(request_object.encoding)\n",
    "print(type(request_object.text))\n",
    "print(request_object.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64ed453b-af60-488e-8896-26dc5da5febb",
   "metadata": {},
   "source": [
    "**Read in bytes with for loop**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f9c6977d-fb85-4af7-9de9-c6ca2138916a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "But soft what light through yonder window breaks\n",
      "It is the east and Juliet is the sun\n",
      "Arise fair sun and kill the envious moon\n",
      "W\n",
      "ho is already sick and pale with grief\n",
      "\n"
     ]
    }
   ],
   "source": [
    "request_object = requests.get('http://data.pr4e.org/romeo.txt', timeout = 1.0)\n",
    "request_object.raise_for_status()  # No error so nothing done.\n",
    "\n",
    "i_count = 0\n",
    "for b_line in request_object:\n",
    "    s_line = b_line.decode()\n",
    "    print(s_line)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3af577b-b9d4-4de3-b326-6392ab854fbc",
   "metadata": {},
   "source": [
    "**`.content`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0feb23b5-d7da-45c6-ab6f-b737a26e0924",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'But soft what light through yonder window breaks\\nIt is the east and Juliet is the sun\\nArise fair sun and kill the envious moon\\nWho is already sick and pale with grief\\n'\n"
     ]
    }
   ],
   "source": [
    "request_object = requests.get('http://data.pr4e.org/romeo.txt', timeout = 1.0)\n",
    "request_object.raise_for_status()  # No error so nothing done.\n",
    "print(request_object.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69a068e0-b2d6-487b-bc24-116bb9b9e38a",
   "metadata": {},
   "source": [
    "**`.iter.content()`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5d0070b7-aa9c-471c-9e3d-b92d06fab649",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('output/requests_byte_file.jpg', 'wb') as file_object:\n",
    "    request_object = requests.get('http://data.pr4e.org/cover3.jpg', timeout = 1.0)\n",
    "    request_object.raise_for_status()  # No error so nothing done.\n",
    "    for b_chunk in request_object.iter_content(chunk_size = 100000):\n",
    "        file_object.write(b_chunk)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae21d37e-1f07-497d-8a8e-8fb2312e627d",
   "metadata": {},
   "source": [
    "- Lastly, note that there are other HTTP requests besides GET\n",
    "\n",
    "Method | Use\n",
    "--- | ---\n",
    "`GET` | Web browsers sends GET to request file/resource from a web server.  The most common command.\n",
    "`POST` | Web browser sends POST to update file/resource on web server\n",
    "`PUT` | Similar to `Post`\n",
    "`HEAD` | Similar to `GET`\n",
    "`DELETE` |Web browser sends DELETE to delete file/resource form web server\n",
    "`PATCH` | \n",
    "`OPTIONS` | Web Browser sends OPTIONS to receive a list of communication options"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe91cfa4-c3b0-43e3-b4eb-c37062f97c95",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46bbafa5-28ac-4f6d-9b58-a0270fef94c4",
   "metadata": {},
   "source": [
    "## Parsing HTML\n",
    "- Once we GET our data, we read it into our script and then parse it.  \n",
    "- **Parse**--conversion of data from the original format to another format that is more useful to us\n",
    "- To parse data properly, we need to know the basic structure of the data.  We'll first look at HTML data.\n",
    "- HTML documents use *tags* and *elements* within their code\n",
    "    1. **Element**--combination of a start **tag**, some content, and an end **tag**. The element includes the start and end tags.\n",
    "```html\n",
    "<tagname>Content goes here</tagname>\n",
    "```\n",
    "    1. **Attributes**--name/value pairs on the start tag of the element.  Optional.  They provide more information about the element.\n",
    "```html\n",
    "<tagname attribute_name=\"value\">Content goes here</tagname>\n",
    "```\n",
    "- These elements are organized in an **element tree** structure.  The tree starts at the \"root\" element and branches to nested \"leaf\"/\"child\" elements/nodes.   Elements at the same level of nested-ness are called siblings.  A parent it the element above the current one.\n",
    "- In the below element tree, note that:\n",
    "    - The root element is `<html>` and there is only one root\n",
    "    - All the elements in the tree are descendants of of `<html>`\n",
    "    - `<html>`'s direct descendants (children one level below) are `<head>` and `<body>`\n",
    "    - `<head>` and `<body>` are siblings\n",
    "    - The parent of `<head>` and `<body>` is `<html>`\n",
    "    - `<head>` and `<body>` have their own children \n",
    "\n",
    "![](images/HTML_tree.png)\n",
    "\n",
    "- Note that HTML does NOT care about indents (no meaning).  However, they are used to signify level on element tree as this dramatically increases readability.\n",
    "- Many HTML documents on the web contain bad HTML code that is not in a standard, correct format. E.g. elements may have missing end tags.  However, many websites forgive these errors and allow the code to function.  This is great for website creators, but bad for someome using regular expressions that assume HTML is in a certain format.  Because HTML can be formatted in a couple ways, and because it can be formatted wrong and still work, trying to use regular expression with HTMl is a bad idea.  Intsead, use Beautiful Soup.\n",
    "- **Beautiful Soup**--library that uses element tree structure to parse HTML and XML, converting it into a more user friendly format.  As Beautiful Soup parses, it fixes errors with the code structure so our tools like RegEx return the expected results.  Its name and domain (https://www.crummy.com/software/BeautifulSoup/bs4/doc/) tease HTML for being so bad.\n",
    "- Beautiful soup transforms HTML documents into 3 main kinds of Python objects.  Each has its own attributes and methods.\n",
    "    1. **BeautifulSoup**--represents the parsed HTML document as a whole.  For most purposes it can be treated similarly to a tag object.\n",
    "    1. **Tag**--corresponds to the element in original HTML document\n",
    "    1. **NavigableString**--corresponds to the content within an element\n",
    "        1. **Comment**--special type of `NavigableString` \n",
    "        1. There are more special types of `NavigabeString` objects\n",
    "\n",
    "Code | Use\n",
    "--- | ---\n",
    "`bs4` | Module.  File is called `beautifulsoup4`, however import using `import bs4`.\n",
    "`bs4.BeautifulSoup()` | Parses HTML or XML document and returns BeautifulSoup object.  First argument is the document, which can be in its encoded bytes format or its decoded Python string format.  Both work.  Second argument is parser.  `html.parser` is built-in and works fine.  `lxml` must be installed, but is faster.  Two others can be seen on website.\n",
    "`.prettify()` | BeautifulSoup or Tag object method.  Like `pprint()`.   Uses insignificant whitespace to print an easier to read text.\n",
    "`.<TAG>` | BeautifulSoup object attribute.  Returns tag object. Returns FIRST element with specified tag.  E.g. if we entered `.p` it would return the element of the first paragraph, but not the second nor third paragraphs.  Tag object includes all descendants and can be visualized as an branch of the element tree.\n",
    "`.contents` | Tag object attribute.  Returns a tag's DIRECT descendants in a list.\n",
    "`.descendants` | Tag object attribute.  Returns ALL tag's descendants in generator object.  Generator object is iterable and can be used in for loop or used with `list()` to create a Python list.\n",
    "`.string` | Tag object attribute.  Returns NavigableString object.  This should then be converted to a Python string data type with `str()`.  If a tag has only one child, and that child is a NavigableString it returns that text as excepted.  If tag's only child is another tag, and *that* tag has a NavigableString child, the the parent tag is considered to have the same NavigableString as the child tag.\n",
    "`.find_all()` | BeautifulSoup or Tag object method.  Same as `<OBJECT>('a')`.  Returns all descendants that match filters in list-like object.  Most popular use of entire library.\n",
    "More | See website for more info on moving sideways to siblings, moving up the tree to parents, filtering, the `.find()` function, and much more."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d69fca38-bfcc-42f4-87c1-8f4a0a4df4e7",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99508a3f-0fad-4f7f-8eb5-5f16f8764e4d",
   "metadata": {},
   "source": [
    "**EXAMPLES**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "67903d61-9f39-4f1e-b846-25ccc59e2b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import bs4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5a505ce-e2b4-4a8a-8470-bfddfba0d89c",
   "metadata": {},
   "source": [
    "**From URL**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e2b8d4fa-5162-4a95-b52e-a398b0c533ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'bs4.BeautifulSoup'>\n"
     ]
    }
   ],
   "source": [
    "# Create a requests object\n",
    "ro = requests.get('http://www.dr-chuck.com/page1.htm', timeout = 1)\n",
    "ro.raise_for_status()\n",
    "\n",
    "# We could use .text or .content attributes here.  Both work.\n",
    "soup = bs4.BeautifulSoup(ro.content, \"html.parser\")\n",
    "print(type(soup))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c7a9484-81ef-4cdd-9e97-25f84ba909a9",
   "metadata": {},
   "source": [
    "**From File Object/Handle**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6b7c81da-f98c-4b71-a7aa-e24e224103cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'bs4.BeautifulSoup'>\n"
     ]
    }
   ],
   "source": [
    "with open('input/html_example.html', 'rt') as file_handle:\n",
    "    soup = bs4.BeautifulSoup(file_handle, \"html.parser\")\n",
    "    print(type(soup))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ab37a1c-f7c9-42e0-b704-8a25c7635708",
   "metadata": {},
   "source": [
    "**BeautifulSoup Object**\n",
    "- Notice how the original is missing end tags for `<html>` and `<body>`\n",
    "- This was parsed and the BeautifulSoup object created.  The BeautifulSoup object now contains closing tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "46ee823e-79bd-4668-a89a-5cf5aa34ae9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'bs4.BeautifulSoup'>\n",
      "\n",
      "<html><head><title>The Dormouse's story</title></head>\n",
      "<body>\n",
      "<p class=\"title\"><b>The Dormouse's story</b></p>\n",
      "<p class=\"story\">Once upon a time there were three little sisters; and their names were\n",
      "<a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">Elsie</a>,\n",
      "<a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\">Lacie</a> and\n",
      "<a class=\"sister\" href=\"http://example.com/tillie\" id=\"link3\">Tillie</a>;\n",
      "and they lived at the bottom of a well.</p>\n",
      "<p class=\"story\">...</p>\n",
      "</body></html>\n",
      "\n",
      "\n",
      "<html>\n",
      " <head>\n",
      "  <title>\n",
      "   The Dormouse's story\n",
      "  </title>\n",
      " </head>\n",
      " <body>\n",
      "  <p class=\"title\">\n",
      "   <b>\n",
      "    The Dormouse's story\n",
      "   </b>\n",
      "  </p>\n",
      "  <p class=\"story\">\n",
      "   Once upon a time there were three little sisters; and their names were\n",
      "   <a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">\n",
      "    Elsie\n",
      "   </a>\n",
      "   ,\n",
      "   <a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\">\n",
      "    Lacie\n",
      "   </a>\n",
      "   and\n",
      "   <a class=\"sister\" href=\"http://example.com/tillie\" id=\"link3\">\n",
      "    Tillie\n",
      "   </a>\n",
      "   ;\n",
      "and they lived at the bottom of a well.\n",
      "  </p>\n",
      "  <p class=\"story\">\n",
      "   ...\n",
      "  </p>\n",
      " </body>\n",
      "</html>\n"
     ]
    }
   ],
   "source": [
    "s_html = \"\"\"\n",
    "<html><head><title>The Dormouse's story</title></head>\n",
    "<body>\n",
    "<p class=\"title\"><b>The Dormouse's story</b></p>\n",
    "\n",
    "<p class=\"story\">Once upon a time there were three little sisters; and their names were\n",
    "<a href=\"http://example.com/elsie\" class=\"sister\" id=\"link1\">Elsie</a>,\n",
    "<a href=\"http://example.com/lacie\" class=\"sister\" id=\"link2\">Lacie</a> and\n",
    "<a href=\"http://example.com/tillie\" class=\"sister\" id=\"link3\">Tillie</a>;\n",
    "and they lived at the bottom of a well.</p>\n",
    "\n",
    "<p class=\"story\">...</p>\n",
    "\"\"\"\n",
    "print(type(soup))\n",
    "soup = bs4.BeautifulSoup(s_html, \"html.parser\")  # BeautifulSoup object\n",
    "print(soup)\n",
    "print('\\n')\n",
    "print(soup.prettify())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dc54842-e09e-407c-a5e8-094830c9a744",
   "metadata": {},
   "source": [
    "**Tag Object**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e8052fa2-e15c-42f7-b52d-c00ffedca432",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'bs4.element.Tag'>\n",
      "<head><title>The Dormouse's story</title></head>\n",
      "\n",
      "\n",
      "<head>\n",
      " <title>\n",
      "  The Dormouse's story\n",
      " </title>\n",
      "</head>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(type(soup.head))  # Tag object\n",
    "print((soup.head))  # Tags are branches that include all descendants\n",
    "print('\\n')\n",
    "print(soup.head.prettify())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83d7e1df-3210-4932-b5ed-f87c40469649",
   "metadata": {},
   "source": [
    "**`.contents`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9f0e75e4-c2b9-47e1-bc94-edeb87d6fb5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "[<title>The Dormouse's story</title>]\n"
     ]
    }
   ],
   "source": [
    "print(type(soup.head.contents))\n",
    "print(soup.head.contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51f71d4d-9d34-4423-966c-8258f81842f6",
   "metadata": {},
   "source": [
    "**`.descendants`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fca9a0c3-696a-4f79-88a7-8802e4b68ccf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'generator'>\n",
      "<title>The Dormouse's story</title>\n",
      "The Dormouse's story\n"
     ]
    }
   ],
   "source": [
    "gen_descendants = soup.head.descendants\n",
    "print(type(gen_descendants))\n",
    "for child in gen_descendants:  # Iterable.\n",
    "    print(child)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0f38d689-bfda-485a-922a-8489fa176030",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<title>The Dormouse's story</title>, \"The Dormouse's story\"]\n"
     ]
    }
   ],
   "source": [
    "gen_descendants = soup.head.descendants\n",
    "print(list(gen_descendants))  # Turned into normal list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb673fc3-2eb2-48cf-ba71-5e43a299e018",
   "metadata": {},
   "source": [
    "**NavigableString Object**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e6aa7563-12f7-4ab7-8bba-47fa1a337d14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'bs4.element.NavigableString'>\n",
      "The Dormouse's story\n"
     ]
    }
   ],
   "source": [
    "tag = soup.title  # Tag object\n",
    "nav_string = tag.string  # NavigableString object\n",
    "print(type(nav_string))\n",
    "print(nav_string)\n",
    "s_nav_string = str(nav_string)  # Convert to Python string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88c532e3-6fac-412a-8bda-91e0900cf2ed",
   "metadata": {},
   "source": [
    "**`.find_all()`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8737e947-df66-497f-91d1-34b08ffa3622",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'bs4.element.ResultSet'>\n",
      "<a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">Elsie</a>\n",
      "<a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\">Lacie</a>\n",
      "<a class=\"sister\" href=\"http://example.com/tillie\" id=\"link3\">Tillie</a>\n"
     ]
    }
   ],
   "source": [
    "found = soup.find_all(\"a\")\n",
    "print(type(found))\n",
    "for tag in found:\n",
    "    print(tag)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69a90514-53bc-4bfe-94de-7ebcf917392d",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beeb7e49-22e1-4cdf-803b-3b1096fd213f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Parsing XML\n",
    "- Data from HTTP GET requests may also be formatted with XML\n",
    "- **XML**--Extensible Markup Language.  \"Wire format\". The \"wire is the internet.  Whatever the original data format, it can be converted to XML (called serialize) sent across the internet (the \"wire\"), and then be converted (de-serialize) into any other format.\n",
    "- Both XML and HTML come from the SGML family of languages. Because of this, both use tags, elements, and trees. Though they both provide a standardized format for storing data, the uses are quite different.\n",
    "- HTML changes how data is displayed so humans can view it. HTML makes data easy for humans to read. XML stores data so that any program on any computer can send data to any other program on any other computer. XML makes data easy for machines to read. Also, HTML tags are predefined. XML tags are not predefined. This means that two programs must agree on the meaning of the XML tags being used.\n",
    "- XML trees share tree structure with HTML as seen in the image below:\n",
    "\n",
    "![](images/XML_tree.png)\n",
    "\n",
    "- The image below is similar to the one above, but shows attributes when the are included for an element:\n",
    "\n",
    "![](images/XML_tree_attributes.gif)\n",
    "\n",
    "- To GET XML data we would send a GET request to a web server that we know outputs XML with a desired element tree structure.  After receiving it we would read in the data and parse it.\n",
    "- We can parse XML data with a module in the Python Standard Library called `xml`\n",
    "\n",
    "Code | Use\n",
    "--- | ---\n",
    "`xml.etree.ElementTree` | Module.  Conventionally, `import xml.etree.ElementTree as ET`.\n",
    "`ET.parse()` | Returns element tree object.  Parameter is file name.\n",
    "`ET.fromstring()` | Returns element tree object.  Parameter is string of text that is structured as an element tree.\n",
    "`.findall()` | Element tree object method.  Returns elements with a specified tag that are direct children of current element.  Parameter is tag to search for.\n",
    "`.find()` | Element tree object method.  Returns *first* child with a specified tag.  Parameter is tag to search for.\n",
    "`.find().text` | Returns the text content from the specified element tag name\n",
    "`.find().get` | Returns the attribute value from the specified element tag name and attribute name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cce46d18-a52b-45ec-9a62-4a21cff72ce0",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1557a29-7bbf-4564-ad4b-206c5c5a0c1f",
   "metadata": {},
   "source": [
    "**EXAMPLES**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bec927bc-a195-490a-8b10-5af440903538",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET  # Use alias as this is long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "afe580c0-b1da-4336-b21e-ea094ebf46b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'xml.etree.ElementTree.Element'>\n",
      "<Element 'name' at 0x000002A1A81FE900>\n",
      "The Black Knight\n",
      "yes\n"
     ]
    }
   ],
   "source": [
    "# The data would normally be gotten from an HTTP GET request, but here, we'll just provide it as a string\n",
    "s_data = \"\"\"\n",
    "<person>\n",
    "    <name>The Black Knight</name>\n",
    "    <phone type=\"intl\">\n",
    "    +1 734 303 4456\n",
    "    </phone>\n",
    "    <email hide=\"yes\"/>\n",
    "</person>\n",
    "\"\"\" # Having triple quotes on separate lines makes code look cleaner, but does create a new line at the top and bottom\n",
    "\n",
    "tree_object = ET.fromstring(s_data)  # Creates an element tree object \n",
    "print(type(tree_object))\n",
    "\n",
    "# Goes down tree and finds name tag\n",
    "print(tree_object.find('name'))\n",
    "\n",
    "# Goes down tree and finds name tag.  Returns just the text content of element.\n",
    "print(tree_object.find('name').text) \n",
    "\n",
    "# Goes down tree and finds email tag.  Returns value associated with hide attribute.\n",
    "print(tree_object.find('email').get('hide'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "823c2d2e-8118-4c82-8284-115e1637e0fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'xml.etree.ElementTree.Element'>\n",
      "<class 'list'>\n",
      "2\n",
      "<class 'xml.etree.ElementTree.Element'>\n",
      "Knights Who Say Ni\n",
      "001\n",
      "2\n",
      "<class 'xml.etree.ElementTree.Element'>\n",
      "Unladen Swallow\n",
      "009\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "# The data would normally be gotten from an HTTP request, but here, we'll just provide it as a string\n",
    "s_data = \"\"\"<stuff>\n",
    "    <users>\n",
    "        <user x=\"2\">\n",
    "            <id>001</id>\n",
    "            <name>Knights Who Say Ni</name>\n",
    "        </user>\n",
    "        <user x=\"7\">\n",
    "             <id>009</id>\n",
    "             <name>Unladen Swallow</name>\n",
    "        </user>\n",
    "    </users>\n",
    "</stuff>\"\"\"\n",
    "\n",
    "tree_object = ET.fromstring(s_data)  # Creates an element tree object\n",
    "print(type(tree_object))\n",
    "\n",
    "# Returns list of tags/elements\n",
    "l_users = tree_object.findall('users/user')  # Finds all user elements under the users element\n",
    "print(type(l_users))\n",
    "print(len(l_users))\n",
    "\n",
    "for user in l_users:\n",
    "    print(type(user))\n",
    "    print(user.find('name').text)  # Name\n",
    "    print(user.find('id').text)  # ID\n",
    "    print(user.get(\"x\"))  # Return value of attribute x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f2ab6f4-90af-4c57-a7b7-1460fae0d666",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68c97ea8-58ad-4f06-9288-a99055289f46",
   "metadata": {},
   "source": [
    "## Parsing JSON\n",
    "- We covered JSON in more detail in the *JSON* section above\n",
    "- Data from HTTP GET requests may also be formatted with JSON\n",
    "- JSON, like XML, is a \"wire format\". The \"wire is the internet. Whatever the original data format, it can be converted to JSON (called serialize) sent across the internet (the \"wire\"), and then be converted (de-serialize) into any other format.\n",
    "- XML is older, more complicated, and more flexible. JSON is newer and simpler. XML has to be parsed with an XML parser. JSON can be parsed by a JavaScript function. JSON is now much more popular than XML.\n",
    "\n",
    "Code | Use\n",
    "--- | ---\n",
    "`json` | Module\n",
    "`json.loads()` | Parses JSON and returns Python.  Converts JSON string to appropriate Python data types.  Can be thought of as \"load **s** tring\".\n",
    "`json.dumps()` | Parses Python and returns JSON. Converts Python data types to JSON string.  Can be thought of as \"dump **s** tring\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d583c462-b0da-47f7-816a-7b4ca72eadec",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b8e295f-17ff-49c6-a89d-3de1077a49cd",
   "metadata": {},
   "source": [
    "**EXAMPLES**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1788ca1c-04ed-42e5-85bf-906c358ec195",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d24982c-acbe-4b9e-adf3-acc3eda1f176",
   "metadata": {},
   "source": [
    "**`loads()`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "55051213-a4a5-46a7-9450-795cceb22f4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'bytes'>\n",
      "<class 'str'>\n",
      "<class 'dict'>\n",
      "2553\n"
     ]
    }
   ],
   "source": [
    "# Loads, then sum certain values\n",
    "\n",
    "request_object = requests.get('http://py4e-data.dr-chuck.net/comments_42.json', timeout = 1.0)\n",
    "request_object.raise_for_status()  # No error so nothing done.\n",
    "b_data = request_object.content\n",
    "print(type(b_data))\n",
    "\n",
    "s_JSON_data = b_data.decode()\n",
    "print(type(s_JSON_data))\n",
    "\n",
    "d_data = json.loads(s_JSON_data)\n",
    "print(type(d_data))\n",
    "\n",
    "i_accumulate = 0\n",
    "for d_withinlist in d_data['comments']:\n",
    "    i_accumulate += d_withinlist['count']\n",
    "print(i_accumulate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "166448cf-54f8-40a5-a29f-545fe06d4904",
   "metadata": {},
   "source": [
    "- If the URL is not working in future, can always use this nested Python dictionary for practice:\n",
    "\n",
    "```python\n",
    "d_data = {'note': 'This file contains the sample data for testing', 'comments': [{'name': 'Romina', 'count': 97}, {'name': 'Laurie', 'count': 97}, {'name': 'Bayli', 'count': 90}, {'name': 'Siyona', 'count': 90}, {'name': 'Taisha', 'count': 88}, {'name': 'Alanda', 'count': 87}, {'name': 'Ameelia', 'count': 87}, {'name': 'Prasheeta', 'count': 80}, {'name': 'Asif', 'count': 79}, {'name': 'Risa', 'count': 79}, {'name': 'Zi', 'count': 78}, {'name': 'Danyil', 'count': 76}, {'name': 'Ediomi', 'count': 76}, {'name': 'Barry', 'count': 72}, {'name': 'Lance', 'count': 72}, {'name': 'Hattie', 'count': 66}, {'name': 'Mathu', 'count': 66}, {'name': 'Bowie', 'count': 65}, {'name': 'Samara', 'count': 65}, {'name': 'Uchenna', 'count': 64}, {'name': 'Shauni', 'count': 61}, {'name': 'Georgia', 'count': 61}, {'name': 'Rivan', 'count': 59}, {'name': 'Kenan', 'count': 58}, {'name': 'Hassan', 'count': 57}, {'name': 'Isma', 'count': 57}, {'name': 'Samanthalee', 'count': 54}, {'name': 'Alexa', 'count': 51}, {'name': 'Caine', 'count': 49}, {'name': 'Grady', 'count': 47}, {'name': 'Anne', 'count': 40}, {'name': 'Rihan', 'count': 38}, {'name': 'Alexei', 'count': 37}, {'name': 'Indie', 'count': 36}, {'name': 'Rhuairidh', 'count': 36}, {'name': 'Annoushka', 'count': 32}, {'name': 'Kenzi', 'count': 25}, {'name': 'Shahd', 'count': 24}, {'name': 'Irvine', 'count': 22}, {'name': 'Carys', 'count': 21}, {'name': 'Skye', 'count': 19}, {'name': 'Atiya', 'count': 18}, {'name': 'Rohan', 'count': 18}, {'name': 'Nuala', 'count': 14}, {'name': 'Maram', 'count': 12}, {'name': 'Carlo', 'count': 12}, {'name': 'Japleen', 'count': 9}, {'name': 'Breeanna', 'count': 7}, {'name': 'Zaaine', 'count': 3}, {'name': 'Inika', 'count': 2}]}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc0b9e25-c932-4151-9cc2-da17aec414e7",
   "metadata": {},
   "source": [
    "**`dumps()`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "02bf20e2-9181-4ec3-90e2-c3fe354db40e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the Python dictionary: {'name': 'John', 'age': 30, 'city': 'New York'}\n",
      "It has been converted (dumps) into a string and modified for readability: {\n",
      "    \"name\"=\"John\", \n",
      "    \"age\"=30, \n",
      "    \"city\"=\"New York\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Dump: Python to JSON.  Format JSON for readability\n",
    "x = {\"name\":\"John\", \"age\":30, \"city\":\"New York\"}\n",
    "print(f'This is the Python dictionary: {x}')\n",
    "\n",
    "# parse\n",
    "y = json.dumps(x, indent=4, separators=(\", \", \"=\"))\n",
    "# Indent puts each dictionary item on a new line and indents 4 spaces.\n",
    "# Separator is symbol used to separate items, followed by symbol used to separate keys from values.\n",
    "\n",
    "print(f'It has been converted (dumps) into a string and modified for readability: {y}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ec388624-06b8-4525-84f5-158460e3bc0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the Python dictionary: {'name': 'John', 'age': 30, 'city': 'New York'}\n",
      "This is the string soted alphabetically by key: {\n",
      "    \"age\": 30,\n",
      "    \"city\": \"New York\",\n",
      "    \"name\": \"John\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Similar to above with sort alphabetically\n",
    "x = {\"name\":\"John\", \"age\":30, \"city\":\"New York\"}\n",
    "print(f'This is the Python dictionary: {x}')\n",
    "\n",
    "# parse\n",
    "y = json.dumps(x, indent=4, sort_keys=True)\n",
    "\n",
    "print(f'This is the string soted alphabetically by key: {y}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4af1f7b3-416a-495e-9dbe-82f6030faf71",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7d17f8d-89b0-4714-97db-f07814738726",
   "metadata": {},
   "source": [
    "### APIs\n",
    "- **API**--Application Programming Interface. It is code (Programming) that allows Applications to Interface (send/receive data) across the Internet.  In other words, a contract between applications that defines the patterns of interaction. \n",
    "- The transfer of data ultimately uses HTTP GET requests and usually includes JSON formatted plaintext data\n",
    "- API protocols are not pre-defined like other data sharing protocols. There is usually a producer of data and a consumer of data.   The producer defines what data they are willing to share, what format the data is in, and how the consumer can make requests to receive the data.\n",
    "- There are a variety of reason why companies, governments, researchers, and non-profits share their data\n",
    "- Producers often limit the number of API requests so that they can control how their data is used.  Often companies sell access to their data .  They do this by requiring keys. Keys are unique sequences that confirm the user has registered/paid to access the data.\n",
    "- Many websites make their data available in JSON format. Facebook, Twitter, Yahoo, Google, Tumblr, Wikipedia, Flickr, Data.gov, Reddit, IMDb, Rotten Tomatoes, LinkedIn, and many other popular sites offer APIs for programs to use.\n",
    "\n",
    "Code | Use\n",
    "--- | ---\n",
    "`?` | A ? at the end of a URL indicates that it can accept parameters. By adding parameters to end of URL, it changes the output of the web server.\n",
    "`urllib.parse.urlencode()` | Differs from normal `encode()` and `decode()`.  The urllib version returns string with \":\" replaced by \"=\", \"spaces\" replaced by \"+\", and \",\" replaced by \"%\" from a specified Python dictionary. Used to format Python dictionary so that it can be added onto a URL with a ? as parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8e979ba-2748-47b5-8265-a146ba39e6b0",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63b50e5c-2dce-4419-a8fb-8df8f3604649",
   "metadata": {},
   "source": [
    "**EXAMPLES**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "dcf7fbc6-c003-4bb2-b4ca-0d681525470b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request, urllib.parse, urllib.error\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "953e852d-dd34-42a9-952e-aa2a498974fc",
   "metadata": {},
   "source": [
    "- Parses to parameters, sends GET request to API, converts JSON string to Python dictionary, and navigates data tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1a775c6e-9371-4851-ae08-cb1d714cbd36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://py4e-data.dr-chuck.net/json?key=42&address=1600+Pennsylvania+Avenue+NW%2C+Washington%2C+DC+20500\n",
      "Retrieved 2325 characters\n",
      "<class 'dict'>\n",
      "Place ID is: ChIJGVtI4by3t4kRr51d_Qm_x58\n"
     ]
    }
   ],
   "source": [
    "s_url_api = 'http://py4e-data.dr-chuck.net/json?'  # Geocode API website that does not require a key\n",
    "\n",
    "s_address = \"1600 Pennsylvania Avenue NW, Washington, DC 20500\"  # A big white house\n",
    "\n",
    "d_param = dict()  # Blank dictionary\n",
    "d_param['key'] = 42  # Key for Dr. Chuck's API\n",
    "d_param['address'] = s_address  # Key value pair added\n",
    "s_url_param = s_url_api + urllib.parse.urlencode(d_param)\n",
    "print(s_url_param)\n",
    "\n",
    "url_handle = urllib.request.urlopen(s_url_param)\n",
    "s_data = url_handle.read().decode()\n",
    "print('Retrieved', len(s_data), 'characters')\n",
    "#print(s_data) # Useful to understand tree structure\n",
    "\n",
    "d_data = json.loads(s_data)  # Turns string into Python dictionary\n",
    "print(type(d_data))\n",
    "\n",
    "\n",
    "place_id = d_data['results'][0]['place_id']\n",
    "# Navigates the tree below\n",
    "print(f'Place ID is: {place_id}')\n",
    "\n",
    "\n",
    "#Tree in form\n",
    "#d_data\n",
    "#    \"results\":List\n",
    "#        Dictionary\n",
    "#            \"address_components\" : List\n",
    "#            \"formated_address\" : \"address, State, Zip, USA\n",
    "#            \"geometry\" : Dictionary\n",
    "#            \"place_id\" : ID\n",
    "#            \"types\" : List\n",
    "#    \"status\": OK"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb158892-4c81-4594-93d0-88281a76b08e",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
